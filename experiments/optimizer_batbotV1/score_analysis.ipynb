{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-10T07:23:28.188731219Z",
     "start_time": "2023-07-10T07:23:28.144231612Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import plotly.express as px\n",
    "from utils import  *\n",
    "from scipy.signal import savgol_filter, find_peaks\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def fitness_max_min_avg(measurements):\n",
    "    \"\"\"\n",
    "    Calculates fitness score of solution from the measured data\n",
    "    :param measurements: np.aray of data provided by read_measurements_df()\n",
    "    :return: score\n",
    "    \"\"\"\n",
    "    sensor_avg = []\n",
    "    for sensor in sensor_col:\n",
    "        peaks, _ = find_peaks(measurements[sensor])\n",
    "        valleys, _ = find_peaks(-measurements[sensor])\n",
    "        max = measurements[sensor][peaks].mean()\n",
    "        min = measurements[sensor][valleys].mean()\n",
    "        sensor_avg.append((max+min)/2)\n",
    "    return abs(np.array(sensor_avg).sum())\n",
    "\n",
    "def fitness_max_min(measurements):\n",
    "    \"\"\"\n",
    "    Calculates fitness score of solution from the measured data\n",
    "    :param measurements: np.aray of data provided by read_measurements_df()\n",
    "    :return: score\n",
    "    \"\"\"\n",
    "    return abs(((measurements.drop('timestamp', axis=1).max()+measurements.drop('timestamp', axis=1).min())/2).sum())\n",
    "\n",
    "def finess_project(measurements):\n",
    "    scores_avg = []\n",
    "    for i in range(1,200):\n",
    "        scores_avg.append(fitness_batbotV1(measurements[:-i], smooth=True))\n",
    "    x = np.arange(len(scores_avg))\n",
    "    fit = np.poly1d(np.polyfit(x, scores_avg,1))\n",
    "    return fit(0)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# assign directory\n",
    "directory = 'data/230706(2)'\n",
    "for i, filename in enumerate(os.listdir(directory)):\n",
    "    if filename[-1] == 'v':\n",
    "        f = os.path.join(directory, filename)\n",
    "        df = pd.read_csv(f)\n",
    "        print(i, df.shape)\n",
    "        y = df[[f'sensor_{i}' for i in range(1,7)]]\n",
    "        df[[f'sensor_{i}' for i in range(1,7)]] = savgol_filter(y, 10, 3, axis=0)\n",
    "        scores_avg = []\n",
    "        scores_max_min = []\n",
    "        scores_max_min_avg = []\n",
    "        for i in range(1,200):\n",
    "            scores_avg.append(fitness_batbotV1(df[:-i]))\n",
    "            scores_max_min.append(fitness_max_min(df[:-i]))\n",
    "            scores_max_min_avg.append(fitness_max_min_avg(df[:-i]))\n",
    "        x = np.arange(len(scores_avg))\n",
    "        fit = np.poly1d(np.polyfit(x, scores_avg,1))\n",
    "        y = fit(x)\n",
    "\n",
    "        plt.plot(scores_avg, label='avg')\n",
    "        plt.plot(y, label=fit(0))\n",
    "        plt.plot(scores_max_min, label='max_min')\n",
    "        plt.plot(scores_max_min_avg, label='max_min_avg')\n",
    "        plt.title(filename)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "from scipy.signal import find_peaks\n",
    "peaks, _ = find_peaks(df.sensor_1)\n",
    "plt.plot(df.timestamp,df.sensor_1)\n",
    "plt.scatter(df.timestamp[peaks],df.sensor_1[peaks])\n",
    "df = pd.read_csv(\"data/230706(1)/1_2_[0.22775696 0.45077319 0.74891196]_0.5779445842122174.csv\")\n",
    "y = df[[f'sensor_{i}' for i in range(1,7)]]\n",
    "df[[f'sensor_{i}' for i in range(1,7)]] = savgol_filter(y, 10, 3, axis=0)\n",
    "df.plot(x='timestamp')\n",
    "# assign directory\n",
    "directory = 'data'\n",
    "\n",
    "sensor_col=[f'sensor_{i}' for i in range(1,7)]\n",
    "#b = pd.read_csv('../../analysis/sensor_calibration.csv')\n",
    "#shift = pd.Series(data=b['data'].to_list(), index=b['index'].to_list())\n",
    "#shift['timestamp'] = 0.0\n",
    "# that directory\n",
    "for i, filename in enumerate(os.listdir(directory)):\n",
    "    if filename[:3] == '0_0' or filename[:3] == '1_2':\n",
    "        f = os.path.join(directory, filename)\n",
    "        df = pd.read_csv(f)\n",
    "        #df = df - shift\n",
    "        #fig = px.line(df, x='timestamp', y = sensor_col, title=f\"score: {abs(df.drop('timestamp', axis=1).mean().sum())}\")\n",
    "        #fig.show()\n",
    "        df['timestamp'] = df['timestamp'] - df['timestamp'][0]\n",
    "df.plot(x='timestamp',title=filename)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pickles to df\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "file = open(f, 'rb')\n",
    "solutions = pickle.load(file)\n",
    "file.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T07:24:51.611616324Z",
     "start_time": "2023-07-10T07:24:51.608378075Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'solutions'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 10\u001B[0m\n\u001B[1;32m      7\u001B[0m f \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(directory, filename)\n\u001B[1;32m      9\u001B[0m file \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(f, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 10\u001B[0m solutions \u001B[38;5;241m=\u001B[39m \u001B[43mpickle\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msolutions\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[1;32m     11\u001B[0m file\u001B[38;5;241m.\u001B[39mclose()\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, sol \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(solutions):\n",
      "\u001B[0;31mKeyError\u001B[0m: 'solutions'"
     ]
    }
   ],
   "source": [
    "# assign directory\n",
    "df_dict_list = []\n",
    "directory = 'data/230710/'\n",
    "gen = 0\n",
    "for i, filename in enumerate(os.listdir(directory)):\n",
    "    if filename[-3:] == 'kle':\n",
    "        f = os.path.join(directory, filename)\n",
    "\n",
    "        file = open(f, 'rb')\n",
    "        solutions = pickle.load(file)['solutions']\n",
    "        file.close()\n",
    "\n",
    "        for i, sol in enumerate(solutions):\n",
    "            df_dict_list.append({'Generation': gen,\n",
    "                             'Id': i,\n",
    "                             'Score': sol[1],\n",
    "                             'Motor': sol[0][0],\n",
    "                             'Neutral': sol[0][1],\n",
    "                             'Amplitude': sol[0][2]})\n",
    "        gen += 1\n",
    "\n",
    "df3 = pd.DataFrame(df_dict_list)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T07:23:56.528169955Z",
     "start_time": "2023-07-10T07:23:56.441478419Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df2['Generation'] = df2['Generation'] + df1['Generation'].iloc[-1] + 1\n",
    "df3['Generation'] = df3['Generation']+ df2['Generation'].iloc[-1] + 1\n",
    "df = pd.concat([df1, df2, df3])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = pd.read_csv('data/230710/0_0.csv')\n",
    "results['test'] = 0\n",
    "for i in range(1,10):\n",
    "    df = pd.read_csv(f'data/230710/0_{i}.csv')\n",
    "    df['test'] = i\n",
    "    results = pd.concat([results, df])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "measurements = results.copy()\n",
    "for test in range(10):\n",
    "    scores_avg = []\n",
    "    for i in range(1, 200):  # for a 5 seconds test we obtain 320 data, doing the analysis with the las 200 showed to\n",
    "        # the most stable\n",
    "        scores_avg.append(fitness_batbotV1(measurements[measurements.test == test][:-i].drop('test', axis=1), smooth=True))\n",
    "    x = np.arange(len(scores_avg))\n",
    "    fit = np.poly1d(np.polyfit(x, scores_avg, 1))\n",
    "    plt.plot(scores_avg)\n",
    "    plt.plot(x,fit(x))\n",
    "#plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(scores_avg)\n",
    "plt.plot(x,fit(x))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
